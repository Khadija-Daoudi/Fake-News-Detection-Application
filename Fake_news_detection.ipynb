{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f24e0124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/macbook/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaiofficial</th>\n",
       "      <th>aaj</th>\n",
       "      <th>aajtak</th>\n",
       "      <th>aamaadmiparty</th>\n",
       "      <th>aamir</th>\n",
       "      <th>ababa</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abia</th>\n",
       "      <th>ability</th>\n",
       "      <th>...</th>\n",
       "      <th>zee</th>\n",
       "      <th>zero</th>\n",
       "      <th>zika</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zithromax</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zookeepers</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6420 rows √ó 5469 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaiofficial  aaj  aajtak  aamaadmiparty     aamir  ababa  abandoned  \\\n",
       "0             0.0  0.0     0.0            0.0  0.000000    0.0        0.0   \n",
       "1             0.0  0.0     0.0            0.0  0.000000    0.0        0.0   \n",
       "2             0.0  0.0     0.0            0.0  0.000000    0.0        0.0   \n",
       "3             0.0  0.0     0.0            0.0  0.000000    0.0        0.0   \n",
       "4             0.0  0.0     0.0            0.0  0.000000    0.0        0.0   \n",
       "...           ...  ...     ...            ...       ...    ...        ...   \n",
       "6415          0.0  0.0     0.0            0.0  0.000000    0.0        0.0   \n",
       "6416          0.0  0.0     0.0            0.0  0.000000    0.0        0.0   \n",
       "6417          0.0  0.0     0.0            0.0  0.000000    0.0        0.0   \n",
       "6418          0.0  0.0     0.0            0.0  0.416388    0.0        0.0   \n",
       "6419          0.0  0.0     0.0            0.0  0.000000    0.0        0.0   \n",
       "\n",
       "      abbott  abia  ability  ...  zee  zero  zika  zinc  zithromax  zombie  \\\n",
       "0        0.0   0.0      0.0  ...  0.0   0.0   0.0   0.0        0.0     0.0   \n",
       "1        0.0   0.0      0.0  ...  0.0   0.0   0.0   0.0        0.0     0.0   \n",
       "2        0.0   0.0      0.0  ...  0.0   0.0   0.0   0.0        0.0     0.0   \n",
       "3        0.0   0.0      0.0  ...  0.0   0.0   0.0   0.0        0.0     0.0   \n",
       "4        0.0   0.0      0.0  ...  0.0   0.0   0.0   0.0        0.0     0.0   \n",
       "...      ...   ...      ...  ...  ...   ...   ...   ...        ...     ...   \n",
       "6415     0.0   0.0      0.0  ...  0.0   0.0   0.0   0.0        0.0     0.0   \n",
       "6416     0.0   0.0      0.0  ...  0.0   0.0   0.0   0.0        0.0     0.0   \n",
       "6417     0.0   0.0      0.0  ...  0.0   0.0   0.0   0.0        0.0     0.0   \n",
       "6418     0.0   0.0      0.0  ...  0.0   0.0   0.0   0.0        0.0     0.0   \n",
       "6419     0.0   0.0      0.0  ...  0.0   0.0   0.0   0.0        0.0     0.0   \n",
       "\n",
       "      zone  zoo  zookeepers  zoom  \n",
       "0      0.0  0.0         0.0   0.0  \n",
       "1      0.0  0.0         0.0   0.0  \n",
       "2      0.0  0.0         0.0   0.0  \n",
       "3      0.0  0.0         0.0   0.0  \n",
       "4      0.0  0.0         0.0   0.0  \n",
       "...    ...  ...         ...   ...  \n",
       "6415   0.0  0.0         0.0   0.0  \n",
       "6416   0.0  0.0         0.0   0.0  \n",
       "6417   0.0  0.0         0.0   0.0  \n",
       "6418   0.0  0.0         0.0   0.0  \n",
       "6419   0.0  0.0         0.0   0.0  \n",
       "\n",
       "[6420 rows x 5469 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string \n",
    "import nltk\n",
    "import seaborn as sns \n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "data = pd.read_excel(\"Data.xlsx\")\n",
    "def Tokenize(text):\n",
    "    return (word_tokenize(text.lower()))\n",
    "data[\"Tokenizing\"]= data[\"tweet\"].apply(lambda x : Tokenize(x))\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def no_stop(text):\n",
    "    text = [c for c in text if c not in stop_words]\n",
    "    return text\n",
    "data[\"not_stop\"]= data[\"Tokenizing\"].apply(lambda x : no_stop(x))\n",
    "\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer()\n",
    "def lemmatize(text):\n",
    "    text = [word_lem.lemmatize(c) for c in text ]\n",
    "    return text\n",
    "data[\"lemmatize\"]=data[\"not_stop\"].apply(lambda x : lemmatize(x))\n",
    "data.drop([\"Tokenizing\",\"not_stop\"] ,axis='columns', inplace=True)\n",
    "def clean(text):\n",
    "    l =[]\n",
    "    for c in text :\n",
    "        c = re.sub('\\[.*?\\]','', c)\n",
    "        c = re.sub(\"\\\\W\",\"\",c) \n",
    "        c = re.sub(r'https.+','', c, flags=re.MULTILINE)\n",
    "        c = re.sub('<.*?>+','', c)\n",
    "        c = re.sub('[%s]' % re.escape(string.punctuation),'', c)\n",
    "        c = re.sub('\\n','', c)\n",
    "        c = re.sub('\\w*\\d\\w*','', c)\n",
    "        c = re.sub('[^a-zA-Z]','',c)\n",
    "        l.append(c)\n",
    "    for i in l:\n",
    "        if i == '':\n",
    "            l.remove(i)\n",
    "        if i == ' ':\n",
    "            l.remove(i)\n",
    "        if i == '  ':\n",
    "            l.remove(i) \n",
    "        if i == '   ':\n",
    "            l.remove(i)  \n",
    "    l = \" \".join([c for c in l])\n",
    "\n",
    "       \n",
    "    return l    \n",
    "data[\"clean\"]=data[\"lemmatize\"].apply(lambda x : clean(x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus=[]\n",
    "for i in range (0, len(data)):\n",
    "  corpus.append(data['clean'][i])\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=2,stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "a = vectorizer.get_feature_names()\n",
    "def all_(text):\n",
    "    text = Tokenize(text)\n",
    "    text = no_stop(text)\n",
    "    text = lemmatize(text)\n",
    "    text = clean(text)\n",
    "    return text\n",
    "df =pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names())\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1ada8480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6420 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0       1.0\n",
       "1       1.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "4       1.0\n",
       "...     ...\n",
       "6415    0.0\n",
       "6416    0.0\n",
       "6417    0.0\n",
       "6418    0.0\n",
       "6419    1.0\n",
       "\n",
       "[6420 rows x 1 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "enc = preprocessing.OrdinalEncoder(categories='auto')\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "data[\"label\"]\n",
    "c = data[\"label\"].to_numpy()\n",
    "c = c.reshape(-1,1)\n",
    "enc.fit(c)\n",
    "b =enc.transform(c)\n",
    "lab = pd.DataFrame(b , columns=[\"label\"])\n",
    "lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18022336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot = pd.concat([df,lab],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "41a493c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MyData(Dataset):\n",
    "  def __init__(self,data,targets):\n",
    "    super(MyData,self)\n",
    "    self.data= data\n",
    "    self.targets = targets\n",
    "  def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "  def __len__(self):\n",
    "        return len(self.targets)\n",
    "X=df_tot.iloc[:,:-1].values\n",
    "Y=df_tot.iloc[:,-1].values\n",
    "\n",
    "ss=StratifiedShuffleSplit(n_splits=1,test_size=0.4,random_state=31)\n",
    "for train_index , group_index in ss.split(X,Y):\n",
    "  Xtrain , Xgroup = X[train_index] , X[group_index]\n",
    "  Ytrain , Ygroup = Y[train_index] , Y[group_index]\n",
    "for test_index , val_index in ss.split(Xgroup,Ygroup):\n",
    "  Xtest , Xval = Xgroup[test_index] , Xgroup[val_index]\n",
    "  Ytest , Yval = Ygroup[test_index] , Ygroup[val_index]\n",
    "sc = StandardScaler()\n",
    "Xtrain = sc.fit_transform(Xtrain)\n",
    "Xtest = sc.fit_transform(Xtest)\n",
    "Xval =  sc.fit_transform(Xval)  \n",
    "\n",
    "\n",
    "Xtrain,Xtest,Xval = map(torch.tensor,(Xtrain,Xtest,Xval))\n",
    "Ytrain , Ytest,Yval = map(torch.tensor,(Ytrain,Ytest,Yval))\n",
    "\n",
    "Xtrain=Xtrain.float()\n",
    "Xtest = Xtest.float()\n",
    "Xval=Xval.float()\n",
    "Ytrain  =Ytrain.float()#Ytrain.type(torch.LongTensor)#Ytrain.float()\n",
    "mydd = MyData(Xtrain,Ytrain)\n",
    "train_loader = DataLoader(dataset = mydd, batch_size=1000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a44388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(output , label):\n",
    "    L=[]\n",
    "    for i in output:\n",
    "        if i >= 0.5:\n",
    "            L.append(1)\n",
    "        else :\n",
    "            L.append(0)\n",
    "    T = label.numpy() \n",
    "    t=0\n",
    "    for i in range(len(T)):\n",
    "        if T[i]==L[i]:\n",
    "            t+=1\n",
    "    return t/len(T)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aab847c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "class NNNNN(nn.Module):\n",
    "  def __init__ (self):\n",
    "    super(NNNNN, self).__init__()\n",
    "    self.l1=nn.Linear(5469 ,100)\n",
    "    self.l2=nn.Linear(100,100)\n",
    "    self.l3=nn.Linear(100,1)\n",
    "    self.relu =nn.ReLU()\n",
    "    self.sig=nn.Sigmoid()\n",
    "    self.init_weights()\n",
    "  def init_weights(self):\n",
    "    torch.nn.init.kaiming_normal_(self.l1.weight)  \n",
    "    torch.nn.init.kaiming_normal_(self.l2.weight)  \n",
    "    torch.nn.init.kaiming_normal_(self.l3.weight)  \n",
    "\n",
    "  def forward(self,x):\n",
    "    out_int = self.l1(x)\n",
    "    out_func = self.relu(out_int)\n",
    "    out_func = self.l2(out_func)\n",
    "    out_func = self.relu(out_func)\n",
    "    out=self.l3(out_func)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "035b0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nttt=NNNNN()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ac40eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train_accuracy: 0.5423, valid_accuracy: 0.5778\n",
      "epoch 1, train_accuracy: 0.7254, valid_accuracy: 0.6673\n",
      "epoch 2, train_accuracy: 0.8462, valid_accuracy: 0.7335\n",
      "epoch 3, train_accuracy: 0.9096, valid_accuracy: 0.7714\n",
      "epoch 4, train_accuracy: 0.9413, valid_accuracy: 0.8035\n",
      "epoch 5, train_accuracy: 0.9648, valid_accuracy: 0.8249\n",
      "epoch 6, train_accuracy: 0.9765, valid_accuracy: 0.8356\n",
      "epoch 7, train_accuracy: 0.9930, valid_accuracy: 0.8434\n",
      "epoch 8, train_accuracy: 0.9953, valid_accuracy: 0.8473\n",
      "epoch 9, train_accuracy: 0.9965, valid_accuracy: 0.8482\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader_ = DataLoader(dataset = mydd, batch_size=1000)\n",
    "loss_ = torch.nn.BCELoss(reduction=\"mean\")\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(nttt.parameters(), lr=0.0003, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "epoch = 10\n",
    "nttt.train()\n",
    "T =[]\n",
    "for ep in range(epoch):\n",
    "    \n",
    "    \n",
    "    for feature , label in train_loader_:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = nttt.forward(feature)\n",
    "        \n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(output,label.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    nttt.eval()\n",
    "    predect = nttt.forward(Xval)\n",
    "    t = compare(output,label)\n",
    "    v=compare(predect,Yval)\n",
    "    print(\"epoch {}, train_accuracy: {:.4f}, valid_accuracy: {:.4f}\".format(ep,t,v ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c53bfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "predectt = nttt(Xtest)\n",
    "print(compare(predectt,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a4e46312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(tweet) : \n",
    "        text = all_(tweet)\n",
    "        tfidf_encoding =vectorizer.transform([text])\n",
    "        tfidf_encodings_array = tfidf_encoding.toarray()\n",
    "        return tfidf_encodings_array\n",
    "def predictt(text):\n",
    "    with torch.no_grad():\n",
    "       \n",
    "       tes=cleaner(text)\n",
    "       #tes=tes.todense()\n",
    "       test= torch.tensor(tes,dtype=torch.float)\n",
    "       output = nttt.forward(test)\n",
    "       if output >= 0.5:\n",
    "            c = 1\n",
    "       else :\n",
    "            c=0;\n",
    "            \n",
    "       return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "\n",
    "root = Tk()\n",
    "root.geometry(\"600x600\")\n",
    "root.title(\" DOcFN \")\n",
    "\n",
    "def Take_input():\n",
    "    INPUT = inputtxt.get(\"1.0\", \"end-1c\")\n",
    "    test = all_(INPUT)\n",
    "    out = predictt(test)\n",
    "    #print(out)\n",
    "    if(out == 1):\n",
    "        \n",
    "        Output.insert(END, 'Real')\n",
    "    else:\n",
    "        \n",
    "        Output.insert(END, 'Fake')\n",
    "\n",
    "l = Label(text = \"Predict your news üòç\")\n",
    "inputtxt = Text(root, height = 25,width = 50,bg = \"light yellow\",borderwidth=1,relief=\"solid\")\n",
    "\n",
    "Output = Text(root, height = 5,width = 25,bg = \"light yellow\",borderwidth=1,relief=\"solid\")\n",
    "\n",
    "Display = Button(root, height = 2,width = 20,text =\"Show\",command = lambda:Take_input())\n",
    "\n",
    "\n",
    "l.pack()\n",
    "inputtxt.pack()\n",
    "Display.pack()\n",
    "Output.pack()\n",
    "\n",
    "\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe14b64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286e629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
